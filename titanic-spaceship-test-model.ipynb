{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":34377,"databundleVersionId":3220602,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.162122Z","iopub.execute_input":"2024-12-08T08:53:18.162625Z","iopub.status.idle":"2024-12-08T08:53:18.171040Z","shell.execute_reply.started":"2024-12-08T08:53:18.162586Z","shell.execute_reply":"2024-12-08T08:53:18.169757Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/spaceship-titanic/sample_submission.csv\n/kaggle/input/spaceship-titanic/train.csv\n/kaggle/input/spaceship-titanic/test.csv\n","output_type":"stream"}],"execution_count":117},{"cell_type":"markdown","source":"# 1. Load dataset and preprocess","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.173714Z","iopub.execute_input":"2024-12-08T08:53:18.174271Z","iopub.status.idle":"2024-12-08T08:53:18.189423Z","shell.execute_reply.started":"2024-12-08T08:53:18.174221Z","shell.execute_reply":"2024-12-08T08:53:18.188224Z"}},"outputs":[],"execution_count":118},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.191978Z","iopub.execute_input":"2024-12-08T08:53:18.192477Z","iopub.status.idle":"2024-12-08T08:53:18.240811Z","shell.execute_reply.started":"2024-12-08T08:53:18.192425Z","shell.execute_reply":"2024-12-08T08:53:18.239617Z"}},"outputs":[],"execution_count":119},{"cell_type":"code","source":"df[['Deck', 'Number', 'Side']] = df['Cabin'].str.split('/', expand=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.242198Z","iopub.execute_input":"2024-12-08T08:53:18.242545Z","iopub.status.idle":"2024-12-08T08:53:18.263073Z","shell.execute_reply.started":"2024-12-08T08:53:18.242509Z","shell.execute_reply":"2024-12-08T08:53:18.261960Z"}},"outputs":[],"execution_count":120},{"cell_type":"code","source":"df.drop(columns=['PassengerId', 'Cabin', 'Name'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.265699Z","iopub.execute_input":"2024-12-08T08:53:18.266703Z","iopub.status.idle":"2024-12-08T08:53:18.279727Z","shell.execute_reply.started":"2024-12-08T08:53:18.266647Z","shell.execute_reply":"2024-12-08T08:53:18.278255Z"}},"outputs":[],"execution_count":121},{"cell_type":"code","source":"mc_homeplanet = df['HomePlanet'].mode()[0]\nmc_cryosleep = df['CryoSleep'].mode()[0]\nmc_destination = df['Destination'].mode()[0]\nmean_age = df['Age'].mean()\nmc_vip = df['VIP'].mode()[0]\nmean_roomservice = df['RoomService'].mean()\nmean_foodcourt = df['FoodCourt'].mean()\nmean_shoppingmall = df['ShoppingMall'].mean()\nmean_spa = df['Spa'].mean()\nmean_vrdeck = df['VRDeck'].mean()\nmc_deck = df['Deck'].mode()[0]\nmc_side = df['Side'].mode()[0]\nmc_number = df['Number'].mode()[0]\ndf.fillna(value={\"HomePlanet\": mc_homeplanet, \"CryoSleep\": mc_cryosleep, \"Destination\": mc_destination, \n                 'Age': mean_age, 'VIP': mc_vip, 'RoomService': 0, \n                 'FoodCourt': 0, 'ShoppingMall': 0,\n                'Spa': 0, 'VRDeck': 0, 'Deck': mc_deck, 'Side': mc_side, 'Number': mc_number}, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.281401Z","iopub.execute_input":"2024-12-08T08:53:18.281877Z","iopub.status.idle":"2024-12-08T08:53:18.319957Z","shell.execute_reply.started":"2024-12-08T08:53:18.281840Z","shell.execute_reply":"2024-12-08T08:53:18.318820Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_24/44276989.py:14: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df.fillna(value={\"HomePlanet\": mc_homeplanet, \"CryoSleep\": mc_cryosleep, \"Destination\": mc_destination,\n","output_type":"stream"}],"execution_count":122},{"cell_type":"code","source":"df = pd.get_dummies(df, columns = ['HomePlanet', 'Destination', 'Deck', 'Side'], drop_first=True)\n#df = df.dropna()\ndf = df.astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.321988Z","iopub.execute_input":"2024-12-08T08:53:18.322432Z","iopub.status.idle":"2024-12-08T08:53:18.341921Z","shell.execute_reply.started":"2024-12-08T08:53:18.322383Z","shell.execute_reply":"2024-12-08T08:53:18.340623Z"}},"outputs":[],"execution_count":123},{"cell_type":"code","source":"y = df['Transported']\nX = df.drop(columns=['Transported'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.343153Z","iopub.execute_input":"2024-12-08T08:53:18.343471Z","iopub.status.idle":"2024-12-08T08:53:18.350481Z","shell.execute_reply.started":"2024-12-08T08:53:18.343440Z","shell.execute_reply":"2024-12-08T08:53:18.349355Z"}},"outputs":[],"execution_count":124},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_train[0:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.354088Z","iopub.execute_input":"2024-12-08T08:53:18.354421Z","iopub.status.idle":"2024-12-08T08:53:18.380284Z","shell.execute_reply.started":"2024-12-08T08:53:18.354389Z","shell.execute_reply":"2024-12-08T08:53:18.379222Z"}},"outputs":[{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"array([[0.00000000e+00, 3.54430380e-01, 0.00000000e+00, 0.00000000e+00,\n        1.98391228e-03, 0.00000000e+00, 3.53219901e-02, 0.00000000e+00,\n        4.32946146e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        1.00000000e+00],\n       [0.00000000e+00, 2.15189873e-01, 0.00000000e+00, 0.00000000e+00,\n        4.31050031e-02, 1.31959816e-03, 0.00000000e+00, 0.00000000e+00,\n        3.03590285e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00],\n       [1.00000000e+00, 3.54430380e-01, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        1.73706441e-01, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        1.00000000e+00],\n       [0.00000000e+00, 2.53164557e-01, 0.00000000e+00, 0.00000000e+00,\n        7.21422645e-05, 1.23020603e-02, 5.25522292e-02, 0.00000000e+00,\n        9.50369588e-01, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00],\n       [1.00000000e+00, 4.55696203e-01, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        9.50369588e-03, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00]])"},"metadata":{}}],"execution_count":125},{"cell_type":"code","source":"def process_data(df):\n    df[['Deck', 'Number', 'Side']] = df['Cabin'].str.split('/', expand=True)\n    df.drop(columns=['PassengerId', 'Cabin', 'Name'], inplace=True)\n    df.fillna(value={\"HomePlanet\": mc_homeplanet, \"CryoSleep\": mc_cryosleep, \"Destination\": mc_destination, \n                 'Age': mean_age, 'VIP': mc_vip, 'RoomService': 0, \n                 'FoodCourt': 0, 'ShoppingMall': 0,\n                'Spa': 0, 'VRDeck': 0, 'Deck': mc_deck, 'Side': mc_side, 'Number': mc_number}, inplace=True)\n    #df = df.dropna()\n    df = pd.get_dummies(df, columns = ['HomePlanet', 'Destination', 'Deck', 'Side'], drop_first=True)\n    df = df.astype(int)\n    df = scaler.transform(df)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.381460Z","iopub.execute_input":"2024-12-08T08:53:18.381781Z","iopub.status.idle":"2024-12-08T08:53:18.388813Z","shell.execute_reply.started":"2024-12-08T08:53:18.381745Z","shell.execute_reply":"2024-12-08T08:53:18.387433Z"}},"outputs":[],"execution_count":126},{"cell_type":"code","source":"X_test = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\ntest_passengerID = X_test['PassengerId']\nX_test = process_data(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.390462Z","iopub.execute_input":"2024-12-08T08:53:18.390792Z","iopub.status.idle":"2024-12-08T08:53:18.449772Z","shell.execute_reply.started":"2024-12-08T08:53:18.390759Z","shell.execute_reply":"2024-12-08T08:53:18.448601Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_24/3595009695.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df.fillna(value={\"HomePlanet\": mc_homeplanet, \"CryoSleep\": mc_cryosleep, \"Destination\": mc_destination,\n","output_type":"stream"}],"execution_count":127},{"cell_type":"markdown","source":"# 2. Evaluate on LogisticRegression Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.linear_model import LogisticRegression\n\nparam_grid_logreg = {'C': [0.01, 0.02, 0.03, 0.1, 1, 10, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]}\n\ngrid_logreg = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid_logreg, cv=5)\ngrid_logreg.fit(X_train, y_train)\n\nprint(\"Best C:\", grid_logreg.best_params_)\nprint(\"Best Accuracy:\", grid_logreg.best_score_)\n#Best C: {'C': 400}\n#Best Accuracy: 0.79522749018614\n\nbest_model = grid_logreg.best_estimator_\ny_pred = best_model.predict(X_val)\n\nprint(\"Accuracy:\", accuracy_score(y_val, y_pred))\n#Accuracy: 0.7826336975273146\n\ny_test = grid_logreg.best_estimator_.predict(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.451325Z","iopub.execute_input":"2024-12-08T08:53:18.451630Z","iopub.status.idle":"2024-12-08T08:53:18.459103Z","shell.execute_reply.started":"2024-12-08T08:53:18.451599Z","shell.execute_reply":"2024-12-08T08:53:18.457953Z"}},"outputs":[{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"'\\nfrom sklearn.linear_model import LogisticRegression\\n\\nparam_grid_logreg = {\\'C\\': [0.01, 0.02, 0.03, 0.1, 1, 10, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]}\\n\\ngrid_logreg = GridSearchCV(LogisticRegression(solver=\\'liblinear\\'), param_grid_logreg, cv=5)\\ngrid_logreg.fit(X_train, y_train)\\n\\nprint(\"Best C:\", grid_logreg.best_params_)\\nprint(\"Best Accuracy:\", grid_logreg.best_score_)\\n#Best C: {\\'C\\': 400}\\n#Best Accuracy: 0.79522749018614\\n'"},"metadata":{}}],"execution_count":128},{"cell_type":"markdown","source":"# 3. Evaluate on DecisionTree Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt_clf = DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)\ndt_clf.fit(X_train, y_train)\n\npath = dt_clf.cost_complexity_pruning_path(X_train, y_train)\nccp_alphas = path.ccp_alphas  # Array of effective alphas\n#ccp_alphas = ccp_alphas[:-1]\n\nparam_grid_dt = {\n    'ccp_alpha': ccp_alphas,\n    'max_depth': [3, 5, 10, None],\n    'min_samples_split': [2, 5, 10]\n}\n\n# 5. Use GridSearchCV\ngrid_search_dt = GridSearchCV(\n    estimator=DecisionTreeClassifier(random_state=42),\n    param_grid=param_grid_dt,\n    cv=5,\n    scoring='accuracy',\n    verbose=1\n)\n\n# 6. Fit the model\ngrid_search_dt.fit(X_train, y_train)\nprint(\"Best Parameters:\", grid_search_dt.best_params_)\nprint(\"Best Accuracy:\", grid_search_dt.best_score_)\n#Best Parameters: {'ccp_alpha': 0.0, 'max_depth': 10, 'min_samples_split': 5}\n#Best Accuracy: 0.7729386756590414\n\nbest_model_dt = grid_search_dt.best_estimator_\ny_pred = best_model_dt.predict(X_val)\n\nprint(\"Test Accuracy:\", accuracy_score(y_val, y_pred))\n#Test Accuracy: 0.7619321449108684\n\ny_test = best_model_dt.predict(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.487873Z","iopub.execute_input":"2024-12-08T08:53:18.488286Z","iopub.status.idle":"2024-12-08T08:53:18.517870Z","shell.execute_reply.started":"2024-12-08T08:53:18.488247Z","shell.execute_reply":"2024-12-08T08:53:18.516767Z"}},"outputs":[{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)","text/html":"<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":131},{"cell_type":"markdown","source":"# 4. Evaluate on AdaBoost Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nbase_estimator = DecisionTreeClassifier(random_state=42)\n\nparam_grid = {\n    'n_estimators': [50, 100, 200, 300],               # Number of weak learners\n    'learning_rate': [0.01, 0.1, 0.5, 1.0],           # Shrinking factor\n    'estimator__max_depth': [1, 2, 3]       # Maximum depth of decision trees\n}\n\nadaboost = AdaBoostClassifier(estimator=base_estimator, random_state=42)\n\ngrid_search_adaboost = GridSearchCV(\n    estimator=adaboost,\n    param_grid=param_grid,\n    scoring='accuracy',\n    cv=5,  # 5-fold cross-validation\n    verbose=1,\n    n_jobs=-1  # Use all available processors\n)\ngrid_search_adaboost.fit(X_train, y_train)\n\nprint(\"Best Parameters:\", grid_search_adaboost.best_params_)\nprint(\"Best Accuracy:\", grid_search_adaboost.best_score_)\n\n#Best Parameters: {'estimator__max_depth': 3, 'learning_rate': 0.1, 'n_estimators': 100}\n#Best Accuracy: 0.8098937155092605\n\nbest_model = grid_search_adaboost.best_estimator_\ny_pred = best_model.predict(X_val)\n\nprint(\"Accuracy:\", accuracy_score(y_val, y_pred))\n#Accuracy: 0.8016101207590569\n\ny_test = best_model.predict(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.561599Z","iopub.execute_input":"2024-12-08T08:53:18.562021Z","iopub.status.idle":"2024-12-08T08:53:18.574709Z","shell.execute_reply.started":"2024-12-08T08:53:18.561983Z","shell.execute_reply":"2024-12-08T08:53:18.573584Z"}},"outputs":[{"execution_count":135,"output_type":"execute_result","data":{"text/plain":"'\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import AdaBoostClassifier\\n\\nbase_estimator = DecisionTreeClassifier(random_state=42)\\n\\nparam_grid = {\\n    \\'n_estimators\\': [50, 100, 200, 300],               # Number of weak learners\\n    \\'learning_rate\\': [0.01, 0.1, 0.5, 1.0],           # Shrinking factor\\n    \\'estimator__max_depth\\': [1, 2, 3]       # Maximum depth of decision trees\\n}\\n\\nadaboost = AdaBoostClassifier(estimator=base_estimator, random_state=42)\\n\\ngrid_search_adaboost = GridSearchCV(\\n    estimator=adaboost,\\n    param_grid=param_grid,\\n    scoring=\\'accuracy\\',\\n    cv=5,  # 5-fold cross-validation\\n    verbose=1,\\n    n_jobs=-1  # Use all available processors\\n)\\ngrid_search_adaboost.fit(X_train, y_train)\\n\\nprint(\"Best Parameters:\", grid_search_adaboost.best_params_)\\nprint(\"Best Accuracy:\", grid_search_adaboost.best_score_)\\n\\n#Best Parameters: {\\'estimator__max_depth\\': 3, \\'learning_rate\\': 0.1, \\'n_estimators\\': 100}\\n#Best Accuracy: 0.8098937155092605\\n'"},"metadata":{}}],"execution_count":135},{"cell_type":"markdown","source":"# 5. Evaluate on Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nparam_grid_rf = {\n    'n_estimators': [150, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt', 'log2']\n}\n\nrf = RandomForestClassifier(random_state=42)\ngrid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\ngrid_search_rf.fit(X_train, y_train)\n\n# Best parameters and score\nprint(f\"Best Parameters: {grid_search_rf.best_params_}\")\nprint(f\"Best Score: {grid_search_rf.best_score_:.2f}\")\n#Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n#Best Score: 0.81\n\nbest_model = grid_search_rf.best_estimator_\ny_pred = best_model.predict(X_val)\n\nprint(\"Accuracy:\", accuracy_score(y_val, y_pred))\n#Accuracy: 0.7947096032202415\n\ny_test = best_model.predict(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.609042Z","iopub.execute_input":"2024-12-08T08:53:18.609479Z","iopub.status.idle":"2024-12-08T08:53:18.625152Z","shell.execute_reply.started":"2024-12-08T08:53:18.609330Z","shell.execute_reply":"2024-12-08T08:53:18.623942Z"}},"outputs":[{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"'\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\nparam_grid_rf = {\\n    \\'n_estimators\\': [150, 200, 300],\\n    \\'max_depth\\': [None, 10, 20, 30],\\n    \\'min_samples_split\\': [2, 5, 10],\\n    \\'min_samples_leaf\\': [1, 2, 4],\\n    \\'max_features\\': [\\'sqrt\\', \\'log2\\']\\n}\\n\\nrf = RandomForestClassifier(random_state=42)\\ngrid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, scoring=\\'accuracy\\', n_jobs=-1)\\ngrid_search_rf.fit(X_train, y_train)\\n\\n# Best parameters and score\\nprint(f\"Best Parameters: {grid_search_rf.best_params_}\")\\nprint(f\"Best Score: {grid_search_rf.best_score_:.2f}\")\\n#Best Parameters: {\\'max_depth\\': 10, \\'max_features\\': \\'sqrt\\', \\'min_samples_leaf\\': 2, \\'min_samples_split\\': 5, \\'n_estimators\\': 200}\\n#Best Score: 0.81\\n'"},"metadata":{}}],"execution_count":138},{"cell_type":"markdown","source":"# 6. Evaluate on SVM Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nC_range = np.logspace(-5, 5, base=2, num=11)  # 2^-5 to 2^5\ngamma_range = np.logspace(-5, 5, base=2, num=11)  # 2^-5 to 2^5\n\n# Create the parameter grid\nnlsvm = SVC(kernel=\"rbf\")\ngrid_param = {\n    'C': C_range,\n    'gamma': gamma_range\n}\n\n# Create the GridSearchCV object with K=3 folds\ngrid = GridSearchCV(nlsvm, grid_param, cv=3, scoring='accuracy')\n\n# Fit the model on the training data\ngrid.fit(X_train, y_train)\n\n# Print the best parameters and the corresponding score\nprint(\"Best parameters:\", grid.best_params_)\nprint(\"Best cross-validation score:\", grid.best_score_)\n#Best parameters: {'C': 32.0, 'gamma': 0.25}\n#Best cross-validation score: 0.8014092608570608\n\n# Evaluate the best model on the test set\nbest_model = grid.best_estimator_\n\ny_pred = best_model.predict(X_val)\n\n#print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n#Accuracy: 0.78953421506613\n\ny_test = best_model.predict(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.657509Z","iopub.execute_input":"2024-12-08T08:53:18.657998Z","iopub.status.idle":"2024-12-08T08:53:18.672025Z","shell.execute_reply.started":"2024-12-08T08:53:18.657948Z","shell.execute_reply":"2024-12-08T08:53:18.670842Z"}},"outputs":[{"execution_count":141,"output_type":"execute_result","data":{"text/plain":"'\\nfrom sklearn.svm import SVC\\n\\nC_range = np.logspace(-5, 5, base=2, num=11)  # 2^-5 to 2^5\\ngamma_range = np.logspace(-5, 5, base=2, num=11)  # 2^-5 to 2^5\\n\\n# Create the parameter grid\\nnlsvm = SVC(kernel=\"rbf\")\\ngrid_param = {\\n    \\'C\\': C_range,\\n    \\'gamma\\': gamma_range\\n}\\n\\n# Create the GridSearchCV object with K=3 folds\\ngrid = GridSearchCV(nlsvm, grid_param, cv=3, scoring=\\'accuracy\\')\\n\\n# Fit the model on the training data\\ngrid.fit(X_train, y_train)\\n\\n# Print the best parameters and the corresponding score\\nprint(\"Best parameters:\", grid.best_params_)\\nprint(\"Best cross-validation score:\", grid.best_score_)\\n#Best parameters: {\\'C\\': 32.0, \\'gamma\\': 0.25}\\n#Best cross-validation score: 0.8014092608570608\\n\\n# Evaluate the best model on the test set\\nbest_model = grid.best_estimator_\\n'"},"metadata":{}}],"execution_count":141},{"cell_type":"markdown","source":"# 7. Evaluate on XGBoost Classifier","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nmodel = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n\n# Define parameter grid\nparam_grid = {\n    'n_estimators': [50, 100, 200],      # Number of boosting rounds\n    'max_depth': [3, 5, 7],             # Maximum depth of a tree\n    'learning_rate': [0.01, 0.1, 0.2],  # Learning rate (eta)\n    'subsample': [0.8, 1.0],            # Subsample ratio of the training data\n    'colsample_bytree': [0.8, 1.0],     # Subsample ratio of columns\n}\n\n# Set up GridSearchCV\ngrid_search = GridSearchCV(\n    estimator=model,\n    param_grid=param_grid,\n    scoring='accuracy',    # Metric to optimize\n    cv=3,                  # Cross-validation folds\n    verbose=1,             # Print progress\n    n_jobs=-1              # Use all available cores\n)\n\n# Perform grid search\ngrid_search.fit(X_train, y_train)\n\n# Best parameters and score\nprint(\"Best Parameters:\", grid_search.best_params_)\nprint(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n\n# Evaluate on test set\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_val)\naccuracy = accuracy_score(y_val, y_pred)\nprint(\"Test Accuracy:\", accuracy)\n#Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n#Best Cross-Validation Accuracy: 0.811331607707794\n#Test Accuracy: 0.7975848188614146\n\ny_test = best_model.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:53:18.701709Z","iopub.execute_input":"2024-12-08T08:53:18.702064Z","iopub.status.idle":"2024-12-08T08:54:03.623254Z","shell.execute_reply.started":"2024-12-08T08:53:18.702032Z","shell.execute_reply":"2024-12-08T08:54:03.621602Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 108 candidates, totalling 540 fits\nBest Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\nBest Cross-Validation Accuracy: 0.8119062420803831\nTest Accuracy: 0.7987349051178838\n","output_type":"stream"}],"execution_count":144},{"cell_type":"code","source":"import csv\n\ny_test_TF = [False if v == 0 else True for v in y_test]\ntest_res_df = pd.DataFrame({'PassengerId': test_passengerID, 'Transported': y_test_TF})\ntest_res_df.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:54:03.639267Z","iopub.execute_input":"2024-12-08T08:54:03.640018Z","iopub.status.idle":"2024-12-08T08:54:03.662205Z","shell.execute_reply.started":"2024-12-08T08:54:03.639980Z","shell.execute_reply":"2024-12-08T08:54:03.660814Z"}},"outputs":[],"execution_count":146},{"cell_type":"markdown","source":"# 8. Visualize the results","metadata":{}},{"cell_type":"code","source":"'''\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Data\ndata = {\n    \"Classifier\": [\"Logistic Regression\", \"Decision Tree\", \"AdaBoost\", \"Random Forest\", \"SVM\"],\n    \"Train\": [0.79522749018614, 0.7729386756590414, 0.8098937155092605, 0.81, 0.80141],\n    \"Validation\": [0.7826336975273146, 0.7619321449108684, 0.8016101207590569, 0.7947096032202415, 0.801409260857060],\n    \"Test\": [0.79167, 0.76876, 0.79845, 0.80079, 0.80266],\n}\n\ndf = pd.DataFrame(data)\n\n# Visualization\nx = np.arange(len(df[\"Classifier\"]))  # Label locations\nwidth = 0.25  # Bar width\n\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Bars\nax.bar(x - width, df[\"Train\"], width, label=\"Train\", color=\"skyblue\")\nax.bar(x, df[\"Validation\"], width, label=\"Validation\", color=\"orange\")\nax.bar(x + width, df[\"Test\"], width, label=\"Test\", color=\"green\")\n\n# Labels and Title\nax.set_xlabel(\"Classifiers\")\nax.set_ylabel(\"Accuracy\")\nax.set_title(\"Classifier Performance Comparison\")\nax.set_xticks(x)\nax.set_xticklabels(df[\"Classifier\"], rotation=45, ha=\"right\")\nax.legend()\n\nplt.tight_layout()\nplt.show()\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:54:03.663816Z","iopub.execute_input":"2024-12-08T08:54:03.664321Z","iopub.status.idle":"2024-12-08T08:54:03.673632Z","shell.execute_reply.started":"2024-12-08T08:54:03.664276Z","shell.execute_reply":"2024-12-08T08:54:03.672262Z"}},"outputs":[{"execution_count":147,"output_type":"execute_result","data":{"text/plain":"'\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n\\n# Data\\ndata = {\\n    \"Classifier\": [\"Logistic Regression\", \"Decision Tree\", \"AdaBoost\", \"Random Forest\", \"SVM\"],\\n    \"Train\": [0.79522749018614, 0.7729386756590414, 0.8098937155092605, 0.81, 0.80141],\\n    \"Validation\": [0.7826336975273146, 0.7619321449108684, 0.8016101207590569, 0.7947096032202415, 0.801409260857060],\\n    \"Test\": [0.79167, 0.76876, 0.79845, 0.80079, 0.80266],\\n}\\n\\ndf = pd.DataFrame(data)\\n\\n# Visualization\\nx = np.arange(len(df[\"Classifier\"]))  # Label locations\\nwidth = 0.25  # Bar width\\n\\nfig, ax = plt.subplots(figsize=(10, 6))\\n\\n# Bars\\nax.bar(x - width, df[\"Train\"], width, label=\"Train\", color=\"skyblue\")\\nax.bar(x, df[\"Validation\"], width, label=\"Validation\", color=\"orange\")\\nax.bar(x + width, df[\"Test\"], width, label=\"Test\", color=\"green\")\\n\\n# Labels and Title\\nax.set_xlabel(\"Classifiers\")\\nax.set_ylabel(\"Accuracy\")\\nax.set_title(\"Classifier Performance Comparison\")\\nax.set_xticks(x)\\nax.set_xticklabels(df[\"Classifier\"], rotation=45, ha=\"right\")\\nax.legend()\\n\\nplt.tight_layout()\\nplt.show()\\n'"},"metadata":{}}],"execution_count":147}]}